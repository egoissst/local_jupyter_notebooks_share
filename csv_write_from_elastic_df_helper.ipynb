{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_ELASTIC_URL = \"http://192.168.36.98/mytimes/elasticCommentQuery?sort=desc&appKey=TOI,ET&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED\"\n",
    "BATCH_SIZE_PARAM = 250\n",
    "# ITER_BUFFER = 2\n",
    "CSV_FILE_NAME = '/Users/yash.dalmia/elasticComments.csv'\n",
    "DEFAULT_FIELDS = ['C_T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startEpoch = None\n",
    "endEpoch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "import math\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonFromUrl(url_param):\n",
    "    with urllib.request.urlopen(url_param) as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNewCsv(file_path = CSV_FILE_NAME):\n",
    "    with open(file_path, 'w+') as writeFile:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCsvListFromListComments(list_comments, fields_to_take):\n",
    "    \n",
    "    csv_list = []\n",
    "    for x in list_comments:\n",
    "        if 'C_T' in x:\n",
    "            list1 = []\n",
    "            for fieldStr in fields_to_take:\n",
    "                if \".\" in fieldStr:\n",
    "                    fieldStrArr = fieldStr.split(\".\")\n",
    "                    if fieldStrArr[0] in x and fieldStrArr[1] in x[fieldStrArr[0]]:\n",
    "                        list1.append(x[fieldStrArr[0]][fieldStrArr[1]])\n",
    "                    else:\n",
    "                        list1.append(\"\")\n",
    "                elif fieldStr in x:\n",
    "                    list1.append(x[fieldStr])\n",
    "                else:\n",
    "                    list1.append(\"\")\n",
    "            csv_list.append(list1)\n",
    "            \n",
    "    return csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModifiedUrl(url, from_param, size_param, startEpoch=None, endEpoch=None):\n",
    "    result_url = url + \"&from=\" + str(from_param) + \"&size=\" + str(size_param)\n",
    "    if (startEpoch!=None and endEpoch!=None):\n",
    "        result_url = result_url + \"&sDateEpoch=\" + str(startEpoch) + \"&eDateEpoch=\" + str(endEpoch)\n",
    "    return result_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModifiedUrlDate(url, startEpoch=None, endEpoch=None):\n",
    "#     result_url = url + \"&from=\" + str(from_param) + \"&size=\" + str(size_param)\n",
    "    result_url = url\n",
    "    if (startEpoch!=None and endEpoch!=None):\n",
    "        result_url = result_url + \"&sDateEpoch=\" + str(startEpoch) + \"&eDateEpoch=\" + str(endEpoch)\n",
    "    return result_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendUrlResultToCsv(url, fields_to_take, size_param, file_path, force = False, to_download_till = None):\n",
    "    \n",
    "    final_url = getModifiedUrl(url, 0, size_param)\n",
    "    json_raw_response = getJsonFromUrl(final_url)\n",
    "\n",
    "    total_comment_count = json_raw_response['hits']['total']\n",
    "    \n",
    "    ELASTIC_LIMIT = 10000\n",
    "    if (to_download_till != None and to_download_till < total_comment_count):\n",
    "        total_comment_count = to_download_till\n",
    "        \n",
    "    if (total_comment_count > ELASTIC_LIMIT):\n",
    "        print(\"total_comment_count greater than 10000: %d\" %(total_comment_count))\n",
    "        if ~force:\n",
    "            print(\"aborting\")\n",
    "            return\n",
    "        else:\n",
    "            total_comment_count = ELASTIC_LIMIT\n",
    "        \n",
    "    \n",
    "    num_iters = math.ceil(total_comment_count/size_param)\n",
    "#     num_iters = num_iters + ITER_BUFFER\n",
    "\n",
    "    print(\"total_count : %d\" %(total_comment_count))\n",
    "    print(\"num_iters : %d\" %(num_iters))\n",
    "\n",
    "    for iter_val in range(0, num_iters, 1):\n",
    "        print(\"iteration : %d\" %(iter_val))\n",
    "        from_val = iter_val * size_param\n",
    "        final_url = getModifiedUrl(url, from_val, size_param)\n",
    "        json_raw_response = getJsonFromUrl(final_url)\n",
    "        list_comments = [x['_source'] for x in json_raw_response['hits']['hits']]\n",
    "        \n",
    "        csv_list = getCsvListFromListComments(list_comments, fields_to_take)\n",
    "        df_csv = pd.DataFrame(csv_list, columns = fields_to_take)\n",
    "        \n",
    "        with open(file_path, 'a', encoding='utf-8') as f:\n",
    "            df_csv.to_csv(f, index = False, header=f.tell()==0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_url_result(url, fields_to_take, size_param, file_path = None, force = False, to_download_till = None):\n",
    "    \n",
    "    final_url = getModifiedUrl(url, 0, size_param)\n",
    "    json_raw_response = getJsonFromUrl(final_url)\n",
    "\n",
    "    total_comment_count = json_raw_response['hits']['total']\n",
    "    \n",
    "    ELASTIC_LIMIT = 10000\n",
    "    if (to_download_till != None and to_download_till < total_comment_count):\n",
    "        total_comment_count = to_download_till\n",
    "        \n",
    "    if (total_comment_count > ELASTIC_LIMIT):\n",
    "        print(\"total_comment_count greater than 10000: %d\" %(total_comment_count))\n",
    "        if ~force:\n",
    "            print(\"aborting\")\n",
    "            return\n",
    "        else:\n",
    "            total_comment_count = ELASTIC_LIMIT\n",
    "        \n",
    "    \n",
    "    num_iters = math.ceil(total_comment_count/size_param)\n",
    "#     num_iters = num_iters + ITER_BUFFER\n",
    "\n",
    "    print(\"total_count : %d\" %(total_comment_count))\n",
    "    print(\"num_iters : %d\" %(num_iters))\n",
    "\n",
    "    for iter_val in range(0, num_iters, 1):\n",
    "        print(\"iteration : %d\" %(iter_val))\n",
    "        from_val = iter_val * size_param\n",
    "        final_url = getModifiedUrl(url, from_val, size_param)\n",
    "        json_raw_response = getJsonFromUrl(final_url)\n",
    "        list_comments = [x['_source'] for x in json_raw_response['hits']['hits']]\n",
    "        \n",
    "        csv_list = getCsvListFromListComments(list_comments, fields_to_take)\n",
    "        yield csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_str_pure_hindi(string):\n",
    "#     \"\"\"\n",
    "#     Tokenization/string cleaning for all datasets except for SST.\n",
    "#     Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "#     \"\"\"\n",
    "#     string = re.sub(r\"[^\\u0900\\u0901\\u0902\\u0903\\u0904\\u0905\\u0906\\u0907\\u0908\\u0909\\u090a\\u090b\\u090c\\u090d\\u090e\\u090f\\u0910\\u0911\\u0912\\u0913\\u0914\\u0915\\u0916\\u0917\\u0918\\u0919\\u091a\\u091b\\u091c\\u091d\\u091e\\u091f\\u0920\\u0921\\u0922\\u0923\\u0924\\u0925\\u0926\\u0927\\u0928\\u0929\\u092a\\u092b\\u092c\\u092d\\u092e\\u092f\\u0930\\u0931\\u0932\\u0933\\u0934\\u0935\\u0936\\u0937\\u0938\\u0939\\u093a\\u093b\\u093c\\u093d\\u093e\\u093f\\u0940\\u0941\\u0942\\u0943\\u0944\\u0945\\u0946\\u0947\\u0948\\u0949\\u094a\\u094b\\u094c\\u094d\\u094e\\u094f\\u0950\\u0951\\u0952\\u0953\\u0954\\u0955\\u0956\\u0957\\u0958\\u0959\\u095a\\u095b\\u095c\\u095d\\u095e\\u095f\\u0960\\u0961\\u0962\\u0963\\u0964\\u0965\\u0966\\u0967\\u0968\\u0969\\u096a\\u096b\\u096c\\u096d\\u096e\\u096f\\u0970\\u0971\\u0972\\u0973\\u0974\\u0975\\u0976\\u0977\\u0978\\u0979\\u097a\\u097b\\u097c\\u097d\\u097e\\u097f]\", \" \", string)\n",
    "\n",
    "#     string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "#     return string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_devanagiri(text):\n",
    "    \"\"\"\n",
    "    filters for only devanagiri scripting language\n",
    "    \"\"\"\n",
    "    #re.search returns None if not found\n",
    "    mod_text = re.sub(r\"[^\\u0900-\\u097F]\", \" \", text)\n",
    "    mod_text = re.sub(r\"\\s{2,}\", \" \", mod_text)\n",
    "    return mod_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "#     base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=TOI&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&queryString=_exists_%3AC_T\"\n",
    "    base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=MTO&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&queryString=_exists_%3AC_T\"\n",
    "    \n",
    "    csv_file_path = \"/Users/yash.dalmia/MTO_cmts_30_march_20.csv\"\n",
    "    fields_to_take = ['c_id', 'C_T', 'C_APP_RES']\n",
    "\n",
    "    batch_write_size = 250\n",
    "\n",
    "    createNewCsv(file_path = csv_file_path)\n",
    "\n",
    "    NET_END_TIME_EPOCH = 1585593000000\n",
    "    NUM_DAYS_IN_ONE_ITER = 2\n",
    "    NUM_ITERS = 2\n",
    "\n",
    "    # endEpoch = NET_START_TIME_EPOCH\n",
    "    startEpoch = NET_END_TIME_EPOCH\n",
    "\n",
    "    for iter_val in range(0, NUM_ITERS, 1):\n",
    "        print(\"\\nIter_val : %d\" %(iter_val))\n",
    "        endEpoch = startEpoch\n",
    "        startEpoch = endEpoch - int(NUM_DAYS_IN_ONE_ITER*24*60*60*1000)\n",
    "\n",
    "        url = getModifiedUrlDate(base_url, startEpoch, endEpoch)\n",
    "        print(\"url : \" + url)\n",
    "#         appendUrlResultToCsv(url, fields_to_take = fields_to_take, size_param = batch_write_size, file_path = csv_file_path)\n",
    "        for csv_list in generator_url_result(url, fields_to_take = fields_to_take, size_param = batch_write_size, file_path = csv_file_path):\n",
    "            print(csv_list[1])\n",
    "            c_text = print(csv_list[1][1])\n",
    "            print(c_text)\n",
    "#             print(csv_list[1], old_regex(csv_list[1]), new_regex(csv_list[1]))\n",
    "\n",
    "    print(\"\\nnet startEpoch : \", startEpoch)\n",
    "    print(\"net endEpoch : \", NET_END_TIME_EPOCH)\n",
    "    print(\"csv written to %s\"%(csv_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=NBTO&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&sDate=24%2F4%2F2019&eDate=24%2F4%2F2019\"\n",
    "# url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&sDateEpoch=1548412448000&eDateEpoch=1556188448000&appKey=TOI&queryString=_exists_:SPAM_VAL%20AND%20SPAM_VAL.isSpam:false&multiActorId=6179270,665245713,14219596,6267354,665046059,549930791,548178454,668244979,663707220,22541448,2366863,2589915,655718924,526173678,659669241,103473849,2515704\"\n",
    "# from_param = 0\n",
    "# size_param = 50\n",
    "# # print(getModifiedUrl(url, from_param, size_param))\n",
    "# csv_file_path = \"data/most_abusive_TOI_last_90_days_25April.csv\"\n",
    "# fields_to_take = ['c_id', 'C_T', 'SPAM_VAL.round_prob']\n",
    "\n",
    "# createNewCsv(file_path = csv_file_path)\n",
    "\n",
    "# appendUrlResultToCsv(url, fields_to_take = fields_to_take, size_param = 250, file_path = csv_file_path)\n",
    "# print('saved file at {}'.format(csv_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file_path = \"/Users/yash.dalmia/test_cmt.csv\"\n",
    "# createNewCsv(file_path = csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=MTO&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&actorInfo=vikasdc%40rediffmail.com&sDate=1%2F1%2F2019&queryString=_exists_%3AC_T\"\n",
    "# base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=TIMESB&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&sDate=1%2F12%2F2019&eDate=31%2F1%2F2020&queryString=_exists_%3AC_T\"\n",
    "# base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=TOI&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&sDate=23%2F2%2F2020&eDate=24%2F2%2F2020&queryString=_exists_%3AC_T\"\n",
    "# fields_to_take = ['C_T', 'C_D']\n",
    "# fields_to_take = ['c_id','A_D_N', 'C_D', 'msid','A_K', 'C_T']\n",
    "# batch_write_size = 250\n",
    "# appendUrlResultToCsv(base_url, fields_to_take = fields_to_take, size_param = batch_write_size, file_path = csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_epoch_millis_to_date_string(epoch_millis):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(int(epoch_millis)/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['C_D'] = df['C_D'].apply(convert_epoch_millis_to_date_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns = ['F_NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(csv_file_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email_id_text = \"\"\"\n",
    "# meerameera9355@gmail.com\n",
    "# chandukhan810@gmail.com\n",
    "# bbbb07185@gmail.com\n",
    "# asbn470@gmail.com\n",
    "# meerarooy@gmail.com\n",
    "# khanchandu751@gmail.com\n",
    "# aasha3681@gmail.com\n",
    "# mohammedkhan.mk395@gmail.com\n",
    "# Ckha694@gmail.com\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email_id_list = [x for x in email_id_text.split('\\n') if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields_to_take = ['c_id', 'C_D', 'C_T', 'msid', 'IP', 'F_ADD', 'tet']\n",
    "# batch_write_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for email in email_id_list:\n",
    "#     print('email : {}'.format(email))\n",
    "#     encoded_query_str= urllib.parse.quote(email)\n",
    "#     csv_file_path = \"/Users/yash.dalmia/Downloads/\" + email + \"_details.csv\"\n",
    "#     createNewCsv(file_path = csv_file_path)\n",
    "#     base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=TOI&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&actorInfo={}&queryString=_exists_%3AC_T\".format(encoded_query_str)\n",
    "#     appendUrlResultToCsv(base_url, fields_to_take = fields_to_take, size_param = batch_write_size, file_path = csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# get_time = lambda x : time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r['time'] = df_r['C_D'].apply(get_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_time(1560924551196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r = df_r.drop(columns=['C_D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r.rename(index=str, columns={'C_T': 'Comment Text', 'time': 'Time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r.to_csv(csv_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r = pd.read_csv('/Users/yash.dalmia/toirb_all_cmts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_r['C_T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
